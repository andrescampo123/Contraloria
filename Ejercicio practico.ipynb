{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "083aa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# PIPELINE \"CONTRALORIA\" â€” LECTURA, NORMALIZACIÃ“N, QA\n",
    "# ======================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "ROOT      = Path.cwd()\n",
    "DATA_DIR  = ROOT                   # o Path(\"data\")\n",
    "OUT_DIR   = ROOT / \"outputs\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SECOP_FILE     = \"SECOP.csv\"\n",
    "SIIF_FILE      = \"SIFF.xlsx\"\n",
    "DIVIPOLA_FILE  = \"DIVIPOLA.csv\"\n",
    "\n",
    "# ----------------- HELPERS -----------------\n",
    "def hascol(df: pd.DataFrame, col: str) -> bool:\n",
    "    return col in df.columns\n",
    "\n",
    "def _clean_str(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = str(s).strip().lower()\n",
    "    for a,b in [(\"Ã¡\",\"a\"),(\"Ã©\",\"e\"),(\"Ã­\",\"i\"),(\"Ã³\",\"o\"),(\"Ãº\",\"u\")]:\n",
    "        s = s.replace(a,b)\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def clean_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.rename(columns=lambda c: _clean_str(c).replace(\" \", \"_\"))\n",
    "\n",
    "def normalize_money(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    s = str(val).replace(\" \", \"\").replace(\"\\xa0\",\"\")\n",
    "    s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    s = \"\".join(ch for ch in s if ch.isdigit() or ch in \".-\")\n",
    "    try:\n",
    "        x = float(s)\n",
    "        return np.nan if (x < 0 or x > 1e14) else x\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_dane(code, length=5):\n",
    "    if pd.isna(code): return None\n",
    "    s = \"\".join(ch for ch in str(code) if ch.isdigit())\n",
    "    return s.zfill(length) if s else None\n",
    "\n",
    "def normalize_nit(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = \"\".join(ch for ch in str(x) if ch.isdigit())\n",
    "    return s if s else None\n",
    "\n",
    "def parse_date(x):\n",
    "    if pd.isna(x): return pd.NaT\n",
    "    x = str(x).strip()\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\", \"%d-%m-%Y\", \"%m/%d/%Y\"):\n",
    "        try: return pd.to_datetime(x, format=fmt, errors=\"raise\")\n",
    "        except: pass\n",
    "    return pd.to_datetime(x, errors=\"coerce\")\n",
    "\n",
    "def map_modalidad(x):\n",
    "    mapa = {\n",
    "        \"licitacion\":\"licitacion\",\"licitaciÃ³n\":\"licitacion\",\n",
    "        \"seleccion abreviada\":\"seleccion_abreviada\",\n",
    "        \"contratacion directa\":\"contratacion_directa\",\n",
    "        \"minima cuantia\":\"minima_cuantia\",\n",
    "        \"regimen especial\":\"regimen_especial\",\n",
    "        \"concurso de meritos\":\"concurso_meritos\",\"concurso de mÃ©ritos\":\"concurso_meritos\",\n",
    "    }\n",
    "    x = _clean_str(x)\n",
    "    if x is None: return None\n",
    "    return mapa.get(x, x.replace(\" \",\"_\"))\n",
    "def coalesce_duplicate_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Si hay columnas duplicadas (mismo nombre), combina por fila tomando el primer no nulo.\"\"\"\n",
    "    dup_names = df.columns[df.columns.duplicated()].unique()\n",
    "    for name in dup_names:\n",
    "        sub = df.loc[:, df.columns == name]            # todas las columnas con ese nombre\n",
    "        df[name] = sub.bfill(axis=1).iloc[:, 0]        # primer valor no nulo por fila\n",
    "        df.drop(columns=sub.columns[1:], inplace=True) # elimina duplicadas, deja la 1Âª\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5b8523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- LECTURA -----------------\n",
    "def load_divipola() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tu DIVIPOLA.csv viene con toda la lÃ­nea envuelta en comillas y comillas dobles internas.\n",
    "    Se limpia lÃ­nea a lÃ­nea y luego se parsea como CSV con comas.\n",
    "    \"\"\"\n",
    "    raw = Path(DATA_DIR / DIVIPOLA_FILE).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    lines = raw.splitlines()\n",
    "    fixed = []\n",
    "    for line in lines:\n",
    "        s = line.strip()\n",
    "        if s.startswith('\"'): s = s[1:]\n",
    "        if s.endswith('\"'):   s = s[:-1]\n",
    "        s = s.replace('\"\"','\"')\n",
    "        fixed.append(s)\n",
    "    text = \"\\n\".join(fixed)\n",
    "    df = pd.read_csv(io.StringIO(text), sep=\",\", dtype=str)\n",
    "\n",
    "    # columnas reales vistas en tu archivo:\n",
    "    # 'CÃ³digo Departamento','Nombre Departamento','cod_dane','Nombre Municipio', ...\n",
    "    df = clean_colnames(df)\n",
    "    rename = {\n",
    "        \"codigo_departamento\": \"cod_depto\",\n",
    "        \"nombre_departamento\": \"departamento_std\",\n",
    "        \"cod_dane\": \"cod_dane\",\n",
    "        \"nombre_municipio\": \"municipio_std\",\n",
    "    }\n",
    "    df = df.rename(columns={k:v for k,v in rename.items() if k in df.columns})\n",
    "\n",
    "    if not hascol(df, \"cod_dane\"):\n",
    "        raise ValueError(\"DIVIPOLA.csv no trae 'cod_dane' tras la normalizaciÃ³n.\")\n",
    "\n",
    "    df[\"cod_dane\"] = df[\"cod_dane\"].apply(normalize_dane)\n",
    "    if hascol(df, \"departamento_std\"): df[\"departamento_std\"] = df[\"departamento_std\"].apply(_clean_str)\n",
    "    if hascol(df, \"municipio_std\"):    df[\"municipio_std\"]    = df[\"municipio_std\"].apply(_clean_str)\n",
    "\n",
    "    df = df.dropna(subset=[\"cod_dane\"]).drop_duplicates(\"cod_dane\")\n",
    "    keep = [c for c in [\"cod_dane\",\"departamento_std\",\"municipio_std\"] if hascol(df, c)]\n",
    "    return df[keep]\n",
    "\n",
    "def load_secop() -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATA_DIR / SECOP_FILE, sep=\";\", dtype=str, low_memory=False)\n",
    "    df = clean_colnames(df)\n",
    "\n",
    "    rename = {\n",
    "        \"nombre_de_la_entidad\": \"entidad\",\n",
    "        \"nit_de_la_entidad\": \"nit\",\n",
    "        \"departamento_entidad\": \"departamento\",\n",
    "        \"municipio_entidad\": \"municipio\",\n",
    "        \"modalidad_de_contratacion\": \"modalidad\",\n",
    "        \"objeto_del_contrato\": \"objeto\",\n",
    "        \"objeto_del_proceso\": \"objeto\",\n",
    "        \"fecha_de_firma_del_contrato\": \"fecha_firma\",\n",
    "        \"id_proceso\": \"id_proceso\",\n",
    "        \"id_contrato\": \"numero_contrato\",\n",
    "        \"valor_contrato\": \"valor_contrato\",\n",
    "        \"codigo_dane_municipio\": \"cod_dane\",\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in rename.items() if k in df.columns})\n",
    "\n",
    "    # ðŸ”§ COALESCE de columnas duplicadas (causa del error)\n",
    "    df = coalesce_duplicate_columns(df)\n",
    "\n",
    "    # ---- normalizaciones (todas verificando df.columns) ----\n",
    "    if \"valor_contrato\" in df.columns: df[\"valor_contrato\"] = df[\"valor_contrato\"].apply(normalize_money)\n",
    "    if \"nit\"            in df.columns: df[\"nit\"]            = df[\"nit\"].apply(normalize_nit)\n",
    "    if \"fecha_firma\"    in df.columns: df[\"fecha_firma\"]    = df[\"fecha_firma\"].apply(parse_date)\n",
    "    if \"modalidad\"      in df.columns: df[\"modalidad\"]      = df[\"modalidad\"].apply(map_modalidad)\n",
    "    if \"cod_dane\"       in df.columns: df[\"cod_dane\"]       = df[\"cod_dane\"].apply(normalize_dane)\n",
    "\n",
    "    # ---- strings limpios ----\n",
    "    for c in [\"entidad\",\"objeto\",\"departamento\",\"municipio\",\"id_proceso\",\"numero_contrato\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].map(_clean_str)   # map sobre Serie (mÃ¡s seguro que apply)\n",
    "\n",
    "    # ---- vigencia derivada ----\n",
    "    if \"fecha_firma\" in df.columns:\n",
    "        df[\"vigencia\"] = df[\"fecha_firma\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_siif() -> pd.DataFrame:\n",
    "    \"\"\"SIFF.xlsx tiene 2 filas de metadata (AÃ±o Fiscal, etc.).\"\"\"\n",
    "    df = pd.read_excel(DATA_DIR / SIIF_FILE, dtype=str, skiprows=2)\n",
    "    df = clean_colnames(df)\n",
    "\n",
    "    possible = {\n",
    "        \"vigencia\":  [\"vigencia\",\"anio\",\"aÃ±o\",\"ano\"],\n",
    "        \"cod_dane\":  [\"cod_dane\",\"codigo_dane\",\"codigo_municipio\",\"cod_municipio\"],\n",
    "        \"asignado\":  [\"asignado\",\"apropiacion_inicial\",\"presupuesto_asignado\",\"apropiacion\"],\n",
    "        \"ejecutado\": [\"ejecutado\",\"obligaciones\",\"compromisos\",\"devengado\"],\n",
    "    }\n",
    "    for std, cands in possible.items():\n",
    "        for c in cands:\n",
    "            if hascol(df, c):\n",
    "                df.rename(columns={c: std}, inplace=True)\n",
    "                break\n",
    "\n",
    "    for c in [\"asignado\",\"ejecutado\"]:\n",
    "        if hascol(df, c): df[c] = df[c].apply(normalize_money)\n",
    "    if hascol(df, \"cod_dane\"): df[\"cod_dane\"] = df[\"cod_dane\"].apply(normalize_dane)\n",
    "    if hascol(df, \"vigencia\"): df[\"vigencia\"] = pd.to_numeric(df[\"vigencia\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    if {\"asignado\",\"ejecutado\"}.issubset(df.columns):\n",
    "        df[\"pct_ejec\"] = np.where(df[\"asignado\"]>0, df[\"ejecutado\"]/df[\"asignado\"], np.nan)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c42d5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- QA ENGINE -----------------\n",
    "def qa_rules(df, dataset_name) -> pd.DataFrame:\n",
    "    issues = []\n",
    "    y = pd.Timestamp.today().year\n",
    "\n",
    "    if hascol(df, \"valor_contrato\"):\n",
    "        bad = df[df[\"valor_contrato\"].isna() | (df[\"valor_contrato\"]<=0)]\n",
    "        for i,row in bad.iterrows():\n",
    "            issues.append((dataset_name,i,\"valor_contrato\",row.get(\"valor_contrato\"),\">0 y no nulo\"))\n",
    "\n",
    "    if hascol(df, \"vigencia\"):\n",
    "        bad = df[df[\"vigencia\"].isna() | (df[\"vigencia\"]<2008) | (df[\"vigencia\"]>y+1)]\n",
    "        for i,row in bad.iterrows():\n",
    "            issues.append((dataset_name,i,\"vigencia\",row.get(\"vigencia\"),f\"2008..{y+1}\"))\n",
    "\n",
    "    if hascol(df, \"cod_dane\"):\n",
    "        bad = df[df[\"cod_dane\"].isna() | (df[\"cod_dane\"].astype(str).str.len()!=5)]\n",
    "        for i,row in bad.iterrows():\n",
    "            issues.append((dataset_name,i,\"cod_dane\",row.get(\"cod_dane\"),\"5 dÃ­gitos\"))\n",
    "\n",
    "    if {\"vigencia\",\"fecha_firma\"}.issubset(df.columns):\n",
    "        bad = df[(~df[\"fecha_firma\"].isna()) & (~df[\"vigencia\"].isna())\n",
    "                 & ((df[\"fecha_firma\"].dt.year < (df[\"vigencia\"]-1)) |\n",
    "                    (df[\"fecha_firma\"].dt.year > (df[\"vigencia\"]+1)))]\n",
    "        for i,row in bad.iterrows():\n",
    "            issues.append((dataset_name,i,\"fecha_firma\",str(row.get(\"fecha_firma\")),\"AÃ±o â‰ˆ vigencia (Â±1)\"))\n",
    "\n",
    "    return pd.DataFrame(issues, columns=[\"dataset\",\"row_index\",\"columna\",\"valor\",\"regla\"])\n",
    "\n",
    "def dedup_with_report(df: pd.DataFrame, key_cols: list, dataset_name: str):\n",
    "    if not all(c in df.columns for c in key_cols):\n",
    "        return df.copy(), pd.DataFrame({\"dataset\":[dataset_name],\"cantidad\":[0],\"detalle\":[f\"Sin claves {key_cols}\"]})\n",
    "    before = len(df)\n",
    "    mask = df.duplicated(subset=key_cols, keep=\"first\")\n",
    "    df2  = df.drop_duplicates(subset=key_cols, keep=\"first\").copy()\n",
    "    rep  = pd.DataFrame({\n",
    "        \"dataset\":[dataset_name],\n",
    "        \"cantidad\":[int(mask.sum())],\n",
    "        \"detalle\":[f\"Claves {key_cols}. Registros antes={before}, despues={len(df2)}\"]\n",
    "    })\n",
    "    return df2, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3615a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Proceso completo. Revisa carpeta outputs/\n"
     ]
    }
   ],
   "source": [
    "# ----------------- PIPELINE -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Cargar\n",
    "    divi  = load_divipola()\n",
    "    secop = load_secop()\n",
    "    siif  = load_siif()\n",
    "\n",
    "    # 2) QA + deduplicaciÃ³n\n",
    "    qa_secop = qa_rules(secop, \"SECOP\")\n",
    "    qa_siif  = qa_rules(siif,  \"SIIF\")\n",
    "\n",
    "    secop, rep_dups_secop = dedup_with_report(\n",
    "        secop,\n",
    "        key_cols=[c for c in [\"id_proceso\",\"numero_contrato\",\"vigencia\",\"nit\",\"valor_contrato\",\"fecha_firma\"] if hascol(secop, c)],\n",
    "        dataset_name=\"SECOP\"\n",
    "    )\n",
    "    siif = siif.drop_duplicates().copy()\n",
    "\n",
    "    # 3) Enriquecer con DIVIPOLA\n",
    "    if hascol(secop, \"cod_dane\") and secop[\"cod_dane\"].notna().any():\n",
    "        secop = secop.merge(divi, on=\"cod_dane\", how=\"left\")\n",
    "    elif {\"departamento\",\"municipio\"}.issubset(secop.columns):\n",
    "        secop[\"departamento_std\"] = secop[\"departamento\"].apply(_clean_str)\n",
    "        secop[\"municipio_std\"]    = secop[\"municipio\"].apply(_clean_str)\n",
    "        secop = secop.merge(divi, on=[\"departamento_std\",\"municipio_std\"], how=\"left\")\n",
    "\n",
    "    if hascol(siif, \"cod_dane\"):\n",
    "        siif = siif.merge(divi, on=\"cod_dane\", how=\"left\")\n",
    "\n",
    "    # 4) Agregados SECOP + integraciÃ³n con SIIF\n",
    "    if {\"cod_dane\",\"vigencia\",\"valor_contrato\"}.issubset(secop.columns):\n",
    "        secop_agg = (secop\n",
    "                     .groupby([\"cod_dane\",\"vigencia\"], as_index=False)[\"valor_contrato\"]\n",
    "                     .sum()\n",
    "                     .rename(columns={\"valor_contrato\":\"valor_secop\"}))\n",
    "    else:\n",
    "        secop_agg = pd.DataFrame()\n",
    "\n",
    "    resumen = None\n",
    "    if not secop_agg.empty and {\"cod_dane\",\"vigencia\",\"asignado\"}.issubset(siif.columns):\n",
    "        resumen = (siif.merge(secop_agg, on=[\"cod_dane\",\"vigencia\"], how=\"left\")\n",
    "                        .assign(gap=lambda d: np.where(d[\"asignado\"]>0, d[\"valor_secop\"]/d[\"asignado\"], np.nan)))\n",
    "        orden = [\"vigencia\",\"cod_dane\",\"departamento_std\",\"municipio_std\",\n",
    "                 \"asignado\",\"ejecutado\",\"pct_ejec\",\"valor_secop\",\"gap\"]\n",
    "        resumen = resumen[[c for c in orden if c in resumen.columns]]\n",
    "\n",
    "    # 5) Exportes\n",
    "    secop.to_csv(OUT_DIR/\"01_secop_limpio.csv\", index=False, encoding=\"utf-8\")\n",
    "    siif.to_csv(OUT_DIR/\"02_siif_limpio.csv\",  index=False, encoding=\"utf-8\")\n",
    "    if resumen is not None:\n",
    "        resumen.to_csv(OUT_DIR/\"03_resumen_municipal.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    qa_all = pd.concat([d for d in [qa_secop, qa_siif] if not d.empty], ignore_index=True) \\\n",
    "             if (not qa_secop.empty or not qa_siif.empty) else \\\n",
    "             pd.DataFrame(columns=[\"dataset\",\"row_index\",\"columna\",\"valor\",\"regla\"])\n",
    "    qa_all.to_csv(OUT_DIR/\"qa_errores.csv\", index=False, encoding=\"utf-8\")\n",
    "    rep_dups_secop.to_csv(OUT_DIR/\"qa_posibles_duplicados.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    with open(OUT_DIR/\"README_proceso.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(\"== NormalizaciÃ³n ContralorÃ­a ==\\n\")\n",
    "        f.write(f\"SECOP (filas): {len(secop)}\\n\")\n",
    "        f.write(f\"SIIF  (filas): {len(siif)}\\n\")\n",
    "        if resumen is not None: f.write(f\"RESUMEN municipal (filas): {len(resumen)}\\n\")\n",
    "        f.write(f\"QA errores: {len(qa_all)}\\n\")\n",
    "        f.write(f\"Duplicados SECOP eliminados: {int(rep_dups_secop['cantidad'].iloc[0])}\\n\")\n",
    "\n",
    "    print(\"âœ… Proceso completo. Revisa carpeta outputs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
